# QA Reliable RAG with Cohere and Groq
## Reliable-RAG üè∑Ô∏è

*   Created by: Wilfredo Aaron Sosa Ramos
*   Reference: https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb

### Overview

The "Reliable-RAG" method enhances the traditional Retrieval-Augmented Generation (RAG) approach by adding layers of validation and refinement to ensure the accuracy and relevance of retrieved information. This system is designed to process and query web-based documents, encode their content into a vector store, and retrieve the most relevant segments for generating precise and reliable answers. The method incorporates checks for document relevancy, hallucination prevention, and highlights the exact segments used in generating the final response.

### Key Components

1. **Document Loading and Chunking:** 
   - Web-based documents are loaded and split into smaller, manageable chunks to facilitate efficient vector encoding and retrieval.

2. **Vectorstore Creation:**
   - Utilizes Chroma and Cohere embeddings to encode document chunks into a vector store, enabling efficient similarity-based retrieval.

3. **Document Relevancy Check:**
   - Implements a relevance-checking mechanism using a language model to filter out non-relevant documents before answer generation.

4. **Answer Generation:**
   - Employs a language model to generate concise answers based on the relevant documents retrieved.

5. **Hallucination Detection:**
   - A dedicated hallucination detection step ensures that the generated answers are grounded in the retrieved documents, preventing the inclusion of unsupported or erroneous information.

6. **Document Snippet Highlighting:**
   - The system identifies and highlights the specific document segments that were directly used to generate the answer, providing transparency and traceability.

### Motivation

The Reliable-RAG method was developed to address the common challenges faced in traditional RAG systems, such as retrieving irrelevant documents, generating answers that are not grounded in facts, and the lack of transparency in the sources used for answer generation. By adding multiple layers of validation, this method ensures that the answers provided are both accurate and reliable.

### Method Details and Benefits

- **Document Relevancy Filtering:** 
  By using a binary relevancy score generated by a language model, only the most relevant documents are passed on to the answer generation phase, reducing noise and improving the quality of the final answer.

- **Hallucination Check:**
  Before finalizing the answer, the system checks for hallucinations by verifying that the generated content is fully supported by the retrieved documents.

- **Snippet Highlighting:** 
  This feature enhances transparency by showing the exact segments from the retrieved documents that contributed to the final answer.

## Implementation

### Step-by-Step Python Implementation

1. **Import Libraries and Set Environment Variables**
   - Import necessary libraries and set environment variables for LLM and embedding model access.

2. **Create Vectorstore**
   - Load web-based documents, split them into chunks, and create a vector store using Chroma and Cohere embeddings.

3. **Question Query**
   - Define the user query and retrieve the top relevant documents from the vector store.

4. **Check Document Relevancy**
   - Filter out non-relevant documents using a binary relevancy score provided by a language model.

5. **Generate Answer**
   - Use the relevant documents to generate a concise answer to the user query.

6. **Check for Hallucinations**
   - Ensure that the generated answer is fully grounded in the retrieved documents.

7. **Highlight Document Snippets**
   - Identify and highlight the exact segments from the retrieved documents that were used to generate the final answer.

### Additional Considerations

- **Limitations:** The system's performance is dependent on the quality of the embeddings and the effectiveness of the hallucination detection mechanism.
- **Potential Improvements:** Incorporating more sophisticated models for relevancy checking and hallucination detection could further enhance the system's reliability.
- **Specific Use Cases:** This method is particularly useful in domains where factual accuracy and transparency are paramount, such as legal or academic research.
